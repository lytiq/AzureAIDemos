{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TYFJeiEJ5zBE"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/embeddings/OpenAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUEPhQX_5zBF"
   },
   "source": [
    "# OpenAI Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sdc11E3r5zBH"
   },
   "outputs": [],
   "source": [
    "# %pip install llama-index-embeddings-azure-openai==0.3.0 \n",
    "# %pip install llama-index-llms-azure-openai==0.3.0\n",
    "# %pip install llama-index==0.12.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "4s-P3R045zBJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "chLRh_1q5zBL"
   },
   "outputs": [],
   "source": [
    "# get API key and create embeddings\n",
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "\n",
    "\n",
    "embed_model = AzureOpenAIEmbedding(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    deployment_name=\"text-embedding-ada-002\",\n",
    "    api_key=os.environ['AZURE_OPENAI_API_KEY'],\n",
    "    azure_endpoint=os.environ['AZURE_OPENAI_ENDPOINT'],\n",
    "    api_version=os.environ['AZURE_OPENAI_API_VERSION'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings1 = embed_model.get_text_embedding(\n",
    "    \"Azure Open AI uses latest LLM models for text generation\"\n",
    ")\n",
    "\n",
    "embeddings2 = embed_model.get_text_embedding(\n",
    "    \"Azure Open AI combines OpenAI with model governance\"\n",
    ")\n",
    "\n",
    "embeddings3 = embed_model.get_text_embedding(\n",
    "    \"The government is looking to provide better services to the people.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "77hZHXHY5zBL",
    "outputId": "eb274479-58ba-40d9-a7e8-0122529bb7a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8790993374795034\n"
     ]
    }
   ],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "cos_sim = dot(embeddings1, embeddings2)/(norm(embeddings1)*norm(embeddings2))\n",
    "print(cos_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "F1Ig2-oi5zBM",
    "outputId": "37a6eab6-2382-4bc1-fd94-0df27914a733"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7568739825381245\n"
     ]
    }
   ],
   "source": [
    "cos_sim = dot(embeddings2, embeddings3)/(norm(embeddings2)*norm(embeddings3))\n",
    "print(cos_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from llama_index.core import Settings\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "\n",
    "# You need to deploy your own embedding model as well as your own chat completion model\n",
    "llm = AzureOpenAI(\n",
    "    deployment_name='gpt-4o',\n",
    "    model='gpt-4o',\n",
    "    api_key=os.environ['AZURE_OPENAI_API_KEY'],\n",
    "    azure_endpoint=os.environ['AZURE_OPENAI_ENDPOINT'],\n",
    "    api_version=os.environ['AZURE_OPENAI_API_VERSION'],\n",
    ")\n",
    "\n",
    "embed_model = AzureOpenAIEmbedding(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    deployment_name=\"text-embedding-ada-002\",\n",
    "    api_key=os.environ['AZURE_OPENAI_API_KEY'],\n",
    "    azure_endpoint=os.environ['AZURE_OPENAI_ENDPOINT'],\n",
    "    api_version=os.environ['AZURE_OPENAI_API_VERSION'],\n",
    ")\n",
    "\n",
    "# global settings\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from llama_index.core import Document\n",
    "\n",
    "\n",
    "ds = load_dataset(\"rag-datasets/rag-mini-bioasq\", \"text-corpus\")\n",
    "ds = ds['passages'].to_pandas().set_index('id', drop=True)\n",
    "query_set = load_dataset(\"rag-datasets/rag-mini-bioasq\", \"question-answer-passages\")\n",
    "queries = query_set['test'].take(5)\n",
    "\n",
    "# create a subset of the documents for faster testing\n",
    "\n",
    "passages_required = set()\n",
    "[ passages_required.update([int(id) for id in ids[1:-1].split(\", \")]) for ids in query_set['test'].take(15)['relevant_passage_ids'] ];\n",
    "\n",
    "\n",
    "docs = [Document(text=ds.loc[id].passage, metadata = {'id' : id}) for id in passages_required]\n",
    "for x in docs:\n",
    "    x.doc_id = str(x.metadata['id'])\n",
    "    x.excluded_llm_metadata_keys = ['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    " \n",
    "index = VectorStoreIndex.from_documents(docs)\n",
    "\n",
    "# converting vector store to query engine\n",
    "query_engine = index.as_query_engine(similarity_top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Is Hirschsprung disease a mendelian or a multifactorial disorder?\n",
      "Hirschsprung disease is a multifactorial disorder. It exhibits complex inheritance patterns, including non-Mendelian inheritance for the more common short-segment form, and involves multiple genetic loci and modifier genes. While some forms of the disease follow Mendelian inheritance patterns, the overall genetic basis of Hirschsprung disease is highly complex and involves interactions between various genes. > Source (Doc id: 1616ecb1-6e9d-492b-a2c0-45f2ad66a9d6): Hirschsprung's disease (HSCR) is a fairly frequent cause of intestinal \n",
      "obstruction in children. It is characterized as a sex-linked heterogonous \n",
      "disorder with variable severity and incomplete penetrance giving rise to a \n",
      "variable pattern of inheritance. Although Hirschsprung's disease occurs as an \n",
      "isolated phenotype in at least 70% of cases, it is not infrequently associated \n",
      "with a number of congenital abnormalities and associated syndromes, \n",
      "demonstrating a spectrum of congenital anomali...\n",
      "\n",
      "> Source (Doc id: b9483930-139e-430c-b969-c0b05ed3061d): Hirschsprung disease (HSCR), or congenital intestinal aganglionosis, is a common \n",
      "hereditary disorder causing intestinal obstruction, thereby showing considerable \n",
      "phenotypic variation in conjunction with complex inheritance. Moreover, \n",
      "phenotypic assessment of the disease has been complicated since a subset of the \n",
      "observed mutations is also associated with several additional syndromic \n",
      "anomalies. Coding sequence mutations in e.g. RET, GDNF, EDNRB, EDN3, and SOX10 \n",
      "lead to long-segment (L-HS...\n",
      "\n",
      "> Source (Doc id: 4b11ae70-c569-415e-97e3-1c0fe1e5b6f1): Hirschsprung's disease is characterized by the absence of ganglion cells in the \n",
      "myenteric and submucosal plexuses of the gastrointestinal tract. Genetic \n",
      "dissection was successful as nine genes and four loci for Hirschsprung's disease \n",
      "susceptibility were identified. Different approaches were used to find these \n",
      "loci such as classical linkage in large families, identity by descent mapping in \n",
      "an inbred kindred, candidate gene approaches based on naturally occurring mutant \n",
      "mice models, and f...\n"
     ]
    }
   ],
   "source": [
    "# generating query response\n",
    "query = queries[0]['question']\n",
    "print(\"Query:\", query)\n",
    "response = query_engine.query(query)\n",
    "print(response, response.get_formatted_sources(length = 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n",
      "Metadata length (6) is close to chunk size (50). Resulting chunks are less than 50 tokens. Consider increasing the chunk size or decreasing the size of your metadata to avoid this.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>ap</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>mrr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k</th>\n",
       "      <th>splitter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">5</th>\n",
       "      <th>sentance_512_0</th>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.404722</td>\n",
       "      <td>0.374944</td>\n",
       "      <td>0.778461</td>\n",
       "      <td>0.404722</td>\n",
       "      <td>0.454667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_50</th>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.304167</td>\n",
       "      <td>0.453278</td>\n",
       "      <td>0.855455</td>\n",
       "      <td>0.480278</td>\n",
       "      <td>0.410333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_512</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.404722</td>\n",
       "      <td>0.393278</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.424722</td>\n",
       "      <td>0.433500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">10</th>\n",
       "      <th>sentance_512_0</th>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.534722</td>\n",
       "      <td>0.489488</td>\n",
       "      <td>0.633507</td>\n",
       "      <td>0.554722</td>\n",
       "      <td>0.379544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_50</th>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.415000</td>\n",
       "      <td>0.913904</td>\n",
       "      <td>0.879590</td>\n",
       "      <td>0.978333</td>\n",
       "      <td>0.271236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_512</th>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.522222</td>\n",
       "      <td>0.503694</td>\n",
       "      <td>0.646062</td>\n",
       "      <td>0.574722</td>\n",
       "      <td>0.374548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   precision    recall        ap      ndcg  hit_rate       mrr\n",
       "k  splitter                                                                   \n",
       "5  sentance_512_0   0.760000  0.404722  0.374944  0.778461  0.404722  0.454667\n",
       "   sentence_50      0.850000  0.304167  0.453278  0.855455  0.480278  0.410333\n",
       "   token_512        0.800000  0.404722  0.393278  0.800000  0.424722  0.433500\n",
       "10 sentance_512_0   0.553333  0.534722  0.489488  0.633507  0.554722  0.379544\n",
       "   sentence_50      0.816667  0.415000  0.913904  0.879590  0.978333  0.271236\n",
       "   token_512        0.560000  0.522222  0.503694  0.646062  0.574722  0.374548"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core.evaluation import RetrieverEvaluator\n",
    "from llama_index.core.evaluation.retrieval.metrics import resolve_metrics, HitRate, MRR\n",
    "from llama_index.core.node_parser import SentenceSplitter, TokenTextSplitter\n",
    "\n",
    "metric_dict = {}\n",
    "metrics = [\"precision\", \"recall\", \"ap\", \"ndcg\"]\n",
    "metrics = [x() for x in resolve_metrics(metrics)] + [HitRate(use_granular_hit_rate=True), MRR(use_granular_mrr=True)]\n",
    "\n",
    "results_data = []\n",
    "splitters = {'sentance_512_0': SentenceSplitter(chunk_size=512, chunk_overlap=100),\n",
    "             'token_512': TokenTextSplitter(chunk_size=512, chunk_overlap=100)}\n",
    "\n",
    "for splitter_name in splitters.keys():\n",
    "    splitter = splitters[splitter_name]\n",
    "    index = VectorStoreIndex.from_documents(docs, transformations = [splitter])\n",
    "\n",
    "    for k in [5, 10]:\n",
    "        query_engine = index.as_query_engine(similarity_top_k=k)\n",
    "        for row in queries:\n",
    "            row['relevant_passage_ids'] = row['relevant_passage_ids'][1:-1].split(', ')\n",
    "            query = row['question']\n",
    "            retrieved_nodes = query_engine.retrieve(query)\n",
    "            retrieved_passage_ids = [str(node.metadata['id']) for node in retrieved_nodes]\n",
    "            \n",
    "            for metric in metrics:\n",
    "                eval_result = metric.compute(\n",
    "                    query, row['relevant_passage_ids'], retrieved_passage_ids,\n",
    "                )\n",
    "                metric_dict[metric.metric_name] = eval_result.score\n",
    "            \n",
    "            results_data.append({\n",
    "                'splitter': splitter_name,\n",
    "                'k': k,\n",
    "                'query': query,\n",
    "                'retrieved_ids': retrieved_passage_ids,\n",
    "                'relevant_ids': row['relevant_passage_ids'],\n",
    "                **metric_dict\n",
    "            })\n",
    "\n",
    "results_df = pd.DataFrame(results_data)\n",
    "results_df.drop(['query', 'retrieved_ids', 'relevant_ids'], axis=1).groupby(['k','splitter']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Whiplash\\AppData\\Local\\Temp\\ipykernel_5176\\1160412571.py:11: LangChainDeprecationWarning: The class `AzureChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import AzureChatOpenAI``.\n",
      "  evaluator_llm = LangchainLLMWrapper(AzureChatOpenAI(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56fb3a69a43647fda49d3eac25c72267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f27019e611984d8983c867e50a699f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "149d59e5a8b94e169a1c5f505db1d347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e9e39f811814409a99d703105e43f9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>context_recall</th>\n",
       "      <th>llm_context_precision_with_reference</th>\n",
       "      <th>factual_correctness</th>\n",
       "      <th>semantic_similarity</th>\n",
       "      <th>answer_correctness</th>\n",
       "      <th>faithfulness</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k</th>\n",
       "      <th>splitter</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
       "      <th>sentance_512_0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.731111</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.926734</td>\n",
       "      <td>0.590017</td>\n",
       "      <td>0.771429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_512</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.757778</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.922672</td>\n",
       "      <td>0.739000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">10</th>\n",
       "      <th>sentance_512_0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.699524</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.925472</td>\n",
       "      <td>0.536956</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_512</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.689286</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.923493</td>\n",
       "      <td>0.729206</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   context_recall  llm_context_precision_with_reference  \\\n",
       "k  splitter                                                               \n",
       "5  sentance_512_0             0.8                              0.731111   \n",
       "   token_512                  0.8                              0.757778   \n",
       "10 sentance_512_0             0.8                              0.699524   \n",
       "   token_512                  0.8                              0.689286   \n",
       "\n",
       "                   factual_correctness  semantic_similarity  \\\n",
       "k  splitter                                                   \n",
       "5  sentance_512_0                0.658             0.926734   \n",
       "   token_512                     0.690             0.922672   \n",
       "10 sentance_512_0                0.684             0.925472   \n",
       "   token_512                     0.646             0.923493   \n",
       "\n",
       "                   answer_correctness  faithfulness  \n",
       "k  splitter                                          \n",
       "5  sentance_512_0            0.590017      0.771429  \n",
       "   token_512                 0.739000      0.800000  \n",
       "10 sentance_512_0            0.536956      0.800000  \n",
       "   token_512                 0.729206      0.800000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.dataset_schema import SingleTurnSample\n",
    "                            \n",
    "from ragas.metrics import (LLMContextRecall,LLMContextPrecisionWithReference, Faithfulness, \n",
    "                            SemanticSimilarity, NonLLMContextRecall, answer_correctness, FactualCorrectness)\n",
    "from ragas import evaluate, EvaluationDataset\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "\n",
    "evaluator_llm = LangchainLLMWrapper(AzureChatOpenAI(\n",
    "                openai_api_version=os.environ['AZURE_OPENAI_API_VERSION'],\n",
    "                azure_deployment='gpt-4o',\n",
    "                model='gpt-4o',\n",
    "            ))\n",
    "\n",
    "# evaluator_llm = LangchainLLMWrapper(AzureChatOpenAI(\n",
    "#                 openai_api_version=os.environ['AZURE_OPENAI_API_VERSION'],\n",
    "#                 azure_deployment='gpt-35-turbo16k',\n",
    "#                 model='gpt-35-turbo',\n",
    "#             ))\n",
    "\n",
    "evaluator_embeddings = LangchainEmbeddingsWrapper( AzureOpenAIEmbeddings(\n",
    "                openai_api_version=os.environ['AZURE_OPENAI_API_VERSION'],\n",
    "                azure_deployment='text-embedding-ada-002',\n",
    "                model='text-embedding-ada-002',\n",
    "))\n",
    "\n",
    "\n",
    "metrics = [\n",
    "    LLMContextRecall(), # Recall based on claims made in response vs those in reference, uses LLM\n",
    "    LLMContextPrecisionWithReference(), # Precision based on claims made in response vs those in reference, uses LLM\n",
    "    FactualCorrectness(), # F1-Score of claims made in response vs those in reference\n",
    "    SemanticSimilarity(), # embedding based similarity between generated answer and ground truth\n",
    "    answer_correctness,\n",
    "    Faithfulness()\n",
    "]\n",
    "\n",
    "results_data = []\n",
    "splitters = {'sentance_512_0': SentenceSplitter(chunk_size=512, chunk_overlap=100),\n",
    "             'token_512': TokenTextSplitter(chunk_size=512, chunk_overlap=100)}\n",
    "             \n",
    "for splitter_name in splitters.keys():\n",
    "    splitter = splitters[splitter_name]\n",
    "    index = VectorStoreIndex.from_documents(docs, transformations = [splitter])\n",
    "\n",
    "    for k in [5, 10]:\n",
    "        query_engine = index.as_query_engine(similarity_top_k=k)\n",
    "        samples = []\n",
    "        for row in queries:\n",
    "            query = row['question']\n",
    "            response = query_engine.query(query)\n",
    "            retrieved_nodes = response.source_nodes\n",
    "            retrieved_passage_ids = [node.metadata['id'] for node in retrieved_nodes]\n",
    "            retrieved_passages = [ ds.loc[int(id)].passage for id in retrieved_passage_ids ]\n",
    "            relevant_passages = [ ds.loc[int(id)].passage for id in row[\"relevant_passage_ids\"][1:-1].split(', ') ]\n",
    "            \n",
    "            sample = SingleTurnSample(\n",
    "                user_input=query,\n",
    "                reference=row[\"answer\"],\n",
    "                response=response.response,\n",
    "                retrieved_contexts=retrieved_passages,\n",
    "                reference_contexts=relevant_passages,\n",
    "            )\n",
    "            samples.append(sample)\n",
    "\n",
    "        eval_dataset = EvaluationDataset(samples = samples)\n",
    "        results = evaluate(dataset=eval_dataset, metrics=metrics, llm = evaluator_llm, embeddings = evaluator_embeddings)\n",
    "        df = results.to_pandas()\n",
    "        df['k'] = k\n",
    "        df['splitter'] = splitter_name\n",
    "        results_data.append(df)\n",
    "\n",
    "results_df = pd.concat(results_data).reset_index(drop=True)\n",
    "results_df.drop(['user_input','retrieved_contexts','reference_contexts','response','reference'], axis=1).groupby(['k','splitter']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is RANKL secreted from the cells?\n",
      "Yes, RANKL is secreted from the cells.\n",
      "Receptor activator of nuclear factor B ligand (RANKL) is a cytokine predominantly secreted by osteoblasts.\n"
     ]
    }
   ],
   "source": [
    "print(results_df.iloc[-1]['user_input'])\n",
    "print(results_df.iloc[-1]['response'])\n",
    "print(results_df.iloc[-1]['reference'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
