{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from llama_index import Document, ServiceContext\n",
    "from llama_index.embeddings import AzureOpenAIEmbedding\n",
    "from llama_index.node_parser import SimpleNodeParser\n",
    "from llama_index.llms import AzureOpenAI\n",
    "\n",
    "# Initialize Azure OpenAI\n",
    "llm = AzureOpenAI(\n",
    "    engine=\"gpt-35-turbo\",\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_version=\"2023-07-01-preview\"\n",
    ")\n",
    "\n",
    "# Initialize embeddings\n",
    "embed_model = AzureOpenAIEmbedding(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    deployment_name=\"text-embedding-ada-002\",\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_version=\"2023-07-01-preview\"\n",
    ")\n",
    "\n",
    "# Create service context\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=llm,\n",
    "    embed_model=embed_model\n",
    ")\n",
    "\n",
    "# Load documents from folder\n",
    "documents = []\n",
    "folder_path = \"./fundmgmt_data\"\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        with open(os.path.join(folder_path, filename), 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "            doc = Document(text=text, metadata={\"filename\": filename})\n",
    "            documents.append(doc)\n",
    "\n",
    "# Parse documents into nodes/chunks\n",
    "parser = SimpleNodeParser.from_defaults()\n",
    "nodes = parser.get_nodes_from_documents(documents)\n",
    "\n",
    "# Create dictionary with chunks and embeddings\n",
    "vectorstore_dict = {\n",
    "    \"chunks\": [],\n",
    "    \"embeddings\": []\n",
    "}\n",
    "\n",
    "# Get embeddings for each chunk\n",
    "for node in nodes:\n",
    "    vectorstore_dict[\"chunks\"].append(node.text)\n",
    "    embedding = embed_model.get_text_embedding(node.text)\n",
    "    vectorstore_dict[\"embeddings\"].append(embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cody prompt : write a llama-index + Azure OpenAI based code to take a list of Documents, embed them and store in a dictionary of list like this {\"chunks\" : <list_of_chunks>, \"embeddings\" : <corresponding embedding vectors> }, The data is stored in mutliple .txt files in ./fundmgmt_data folder, also add file name to the metadata so that the embeddings also capture that"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
