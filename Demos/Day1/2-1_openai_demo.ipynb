{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile -a ./.env\n",
    "\n",
    "# AZURE_OPENAI_API_KEY=\n",
    "# AZURE_OPENAI_ENDPOINT="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image is a depiction of \"The Last Supper,\" a famous painting by Leonardo da Vinci. The painting shows a large table with a white tablecloth, with a variety of dishes, cups, and food items placed on it. There are several people seated at the table, and they appear to be engaged in conversation and expressive gestures. The interior setting includes a doorway and windows with a view of a landscape outside. The overall composition is a well-known artistic representation of the biblical scene where Jesus dines with his disciples.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import base64\n",
    "\n",
    "# Initialize Azure OpenAI client\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=\"2024-05-01-preview\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "\n",
    "# Function to encode image to base64\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# Path to your image\n",
    "image_path = \"OpenAI_demo_files/the_last_supper.jpeg\"\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "# Create the message with both text and image\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"What can you see in this image? If there are any people, what are they doing?\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Send request to GPT-4V\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\", \n",
    "    messages=messages,\n",
    "    max_tokens=300\n",
    ")\n",
    "\n",
    "# Print the response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n",
      "FileCounts(cancelled=0, completed=1, failed=0, in_progress=0, total=1)\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "import os\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "    api_version=\"2024-05-01-preview\",\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    )\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "  name=\"Financial Analyst Assistant\",\n",
    "  instructions=\"You are an expert financial analyst. Use your knowledge base to answer questions about audited financial statements.\",\n",
    "  model=\"gpt-4o\",\n",
    "  tools=[{\"type\": \"file_search\"}],\n",
    ")\n",
    "\n",
    "# Create a vector store called \"Financial Statements\"\n",
    "vector_store = client.beta.vector_stores.create(name=\"Financial Statements\")\n",
    " \n",
    "# Ready the files for upload to OpenAI\n",
    "file_paths = [\"OpenAI_demo_files/financial_results.pdf\"]\n",
    "file_streams = [open(path, \"rb\") for path in file_paths]\n",
    " \n",
    "# Use the upload and poll SDK helper to upload the files, add them to the vector store,\n",
    "# and poll the status of the file batch for completion.\n",
    "file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "  vector_store_id=vector_store.id, files=file_streams\n",
    ")\n",
    " \n",
    "assistant = client.beta.assistants.update(\n",
    "  assistant_id=assistant.id,\n",
    "  tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
    ")\n",
    "\n",
    "# You can print the status and the file counts of the batch to see the result of this operation.\n",
    "print(file_batch.status)\n",
    "print(file_batch.file_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: What are the major source of revenue for the company?\n",
      "assistant: The major sources of revenue for the company are:\n",
      "\n",
      "1. **Subscription Revenue**: This is the largest source of revenue for the company, amounting to $5.06 billion in the most recent quarter. It includes revenue from the company's main product lines: Creative Cloud, Document Cloud, and Experience Cloud.\n",
      "2. **Product Revenue**: This includes revenue from the sale of products and amounted to $104 million in the most recent quarter.\n",
      "3. **Services and Other Revenue**: This is the revenue generated from professional services, support and training, and other miscellaneous sources. It amounted to $145 million in the most recent quarter【4:3†source】【4:5†source】.\n"
     ]
    }
   ],
   "source": [
    "thread = client.beta.threads.create()\n",
    "\n",
    "# Add a user question to the thread\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"What are the major source of revenue for the company?\"\n",
    ")\n",
    "\n",
    "# Run the thread and poll for the result\n",
    "run = client.beta.threads.runs.create_and_poll(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    "    instructions=\"Please answer based on files provided\",\n",
    ")\n",
    "\n",
    "if run.status == \"completed\":\n",
    "    messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "    for message in messages.data[::-1]:\n",
    "        print(f\"{message.role}: {'/n'.join([x.text.value for x in message.content])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FileCitationAnnotation(end_index=229, file_citation=FileCitation(file_id='assistant-JqjPU1A0JQtarNcnzFwAbNc5'), start_index=217, text='【4:1†source】', type='file_citation'),\n",
       " FileCitationAnnotation(end_index=229, file_citation=FileCitation(file_id='assistant-JqjPU1A0JQtarNcnzFwAbNc5'), start_index=217, text='【4:1†source】', type='file_citation'),\n",
       " FileCitationAnnotation(end_index=328, file_citation=FileCitation(file_id='assistant-JqjPU1A0JQtarNcnzFwAbNc5'), start_index=316, text='【4:1†source】', type='file_citation'),\n",
       " FileCitationAnnotation(end_index=328, file_citation=FileCitation(file_id='assistant-JqjPU1A0JQtarNcnzFwAbNc5'), start_index=316, text='【4:1†source】', type='file_citation'),\n",
       " FileCitationAnnotation(end_index=416, file_citation=FileCitation(file_id='assistant-JqjPU1A0JQtarNcnzFwAbNc5'), start_index=404, text='【4:1†source】', type='file_citation'),\n",
       " FileCitationAnnotation(end_index=416, file_citation=FileCitation(file_id='assistant-JqjPU1A0JQtarNcnzFwAbNc5'), start_index=404, text='【4:1†source】', type='file_citation'),\n",
       " FileCitationAnnotation(end_index=608, file_citation=FileCitation(file_id='assistant-JqjPU1A0JQtarNcnzFwAbNc5'), start_index=596, text='【4:3†source】', type='file_citation'),\n",
       " FileCitationAnnotation(end_index=608, file_citation=FileCitation(file_id='assistant-JqjPU1A0JQtarNcnzFwAbNc5'), start_index=596, text='【4:3†source】', type='file_citation'),\n",
       " FileCitationAnnotation(end_index=720, file_citation=FileCitation(file_id='assistant-JqjPU1A0JQtarNcnzFwAbNc5'), start_index=708, text='【4:3†source】', type='file_citation'),\n",
       " FileCitationAnnotation(end_index=720, file_citation=FileCitation(file_id='assistant-JqjPU1A0JQtarNcnzFwAbNc5'), start_index=708, text='【4:3†source】', type='file_citation')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message.content[0].text.annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add a user question to the thread\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"What are the major source of revenue for the company?\"\n",
    ")\n",
    "\n",
    "# Run the thread and poll for the result\n",
    "run = client.beta.threads.runs.create_and_poll(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    "    instructions=\"Please answer based on files provided\",\n",
    ")\n",
    "\n",
    "if run.status == \"completed\":\n",
    "    messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "    for message in messages.data[::-1]:\n",
    "        print(f\"{message.role}: {'/n'.join([x.text.value for x in message.content])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
